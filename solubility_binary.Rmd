---
title: "solubility_binary"
author: "Alicia Key"
date: "7/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(readr)
library(skimr)
library(printr)
library(ggplot2)
library(tidyr)
library(gridExtra)
library(mlr)
```

In 2004, John Delaney published a paper which studied a method to predict the aqueous solubility of various compounds [(Delaney, 2004)](https://pubs.acs.org/doi/10.1021/ci034243x) . This paper is widely cited in the machine learning and deep learning literature for chemistry applications. It is like a Titanic or MNIST dataset for the chemistry ML community. The data are labeled with the known solubility in log solubility in mol/L.

Starting the with the ESOL method described by Delaney in 2004, there have been multiple discussions of predicting solubility from these data. Here are two of them:

1.	[http://practicalcheminformatics.blogspot.com/2018/09/predicting-aqueous-solubility-its.html](http://practicalcheminformatics.blogspot.com/2018/09/predicting-aqueous-solubility-its.html)
1.	[https://github.com/deepchem/deepchem/blob/master/examples/tutorials/03_Modeling_Solubility.ipynb](https://github.com/deepchem/deepchem/blob/master/examples/tutorials/03_Modeling_Solubility.ipynb)

I used the dataset released in the [deepchem.io project](https://github.com/deepchem/deepchem/blob/master/datasets/delaney-processed.csv)

For this study, my interests are exploratory data analysis and comparing the performance of various models with these data. To simplify the first iteration of this process, I changed this from a regression of a continuous value of solubility into a binary classification. The two classes are:

1. Those compounds with solubility higher than the median
1. Those compounds with a solubility lower than the median

The solubility data underlying these two classes are measured in log(g/mol).

## Data Preparation and Feature Extraction

The goal of the original 2004 study was to predict the solubility of compounds from SMILES strings. SMILES strings represent the strucuture of a molecule. In the study, these strings were used to calculate several intermediate numeric variables that could then be used to predict solubility. The most significant predictors noted in the abstract are the molecular weight and number of rotatable bonds. I was also interested in the contribution of polar surface area as well.

From the 2004 study, here is an explanation of these variables:

| Variable name | Units | Description |
|---------------|-------|-------------|
| Molecular Weight | g / mol | the molecular weight of the compound
| Number of Rotatable Bonds | unitless | The number of rotatable bonds in the compund, as calculated by the patterns in the SMILES string `[!X1]-,)- [$([C.;X4])]-&!@[$([C.;X4])]-[!X1], [!X1]:c-&!@[$([C.;X4])]-[!X1], [!X1]-,)C-&!@[$([N.;X4])]-[!X1], [!X1]-[$([C.;X4])]-&!@[$([N.;X3])]- [!X1], [!X1]-[$([C.;X4])]-&!@[$([O.;X2])]-[!X1]`
| Polar Surface Area | Ã…<sup>2</sup> | The surface area of the polar atoms of the compound. [See Wikipedia for details](https://en.wikipedia.org/wiki/Polar_surface_area) 

``` {r message = FALSE, include = FALSE}
solubility <- as_tibble(read.csv("data/delaney-original.csv"))

median_solubility = median(solubility$measured.log.solubility.in.mols.per.litre)

solubilityBinary <- solubility %>%
  select(-ESOL.predicted.log.solubility.in.mols.per.litre) %>%
  select(-smiles) %>%
  mutate(solubility.above.or.below.median = 
           ifelse(measured.log.solubility.in.mols.per.litre <= median_solubility, 0, 1)) %>%
  select(Molecular.Weight, 
         Number.of.Rotatable.Bonds, 
         Polar.Surface.Area,
         solubility.above.or.below.median) %>%
  mutate_at(.vars = "solubility.above.or.below.median", .funs = factor)

## 75% of the sample size
smp_size <- floor(0.75 * nrow(solubilityBinary))

## set the seed to make your partition reproducible
set.seed(123)
train_ind <- sample(seq_len(nrow(solubilityBinary)), size = smp_size)

train <- solubilityBinary[train_ind, ]
test <- solubilityBinary[-train_ind, ]
```


### Classes

Two classes are stored in the variable `solubility.above.or.below.median`. 1 signifies solubility above the median and 0 signifies solubikity below the median. The underlying solubility is measured in units of log(g/mol). Class counts are as follows:

``` {r echo = FALSE}
train %>%
  count(solubility.above.or.below.median)
```

### Distributions of predictor variables

``` {r, fig.height = 2, fig.width = 7, fig.align = "center", echo = FALSE, fig.cap = "Figure 1: Histograms of predictor variables"}
p1 <- ggplot(train, aes(x = Molecular.Weight)) +
  geom_histogram(bins = 10) +
  ylim(0, 600) +
  ggtitle("Molecular Weight") +
  xlab("g/mol")

p2 <- ggplot(train, aes(x = Number.of.Rotatable.Bonds)) +
  geom_histogram(bins = 10) +
  ylim(0, 600) +
  ggtitle("Rotatable Bonds") +
  xlab("bonds")

p3 <- ggplot(train, aes(x = Polar.Surface.Area)) +
  geom_histogram(bins = 10) +
  ylim(0, 600) +
  ggtitle("Polar Surface Area") +
  xlab("sq. angstroms")

grid.arrange(p1, p2, p3, nrow = 1)
```

## Exploratory Data Visualization

Since my predictor variables are number of rotatable bonds, polar surface area, and molecular weight, I plotted these variables and labels on scatter plots to see the shape of the data. 

``` {r echo = FALSE, fig.width = 10, fig.height = 5, "Figure 2: Exploratory analysis of solubility"}
ggplot(train, aes(x = Molecular.Weight, 
                  y = Number.of.Rotatable.Bonds, 
                  shape = solubility.above.or.below.median,
                  color = solubility.above.or.below.median,
                  size = Polar.Surface.Area)) +
  geom_point(alpha = 0.5) +
  ggtitle("Rotatable Bonds vs Molecular Weight", 
          subtitle = "All solubilities") +
  xlab("molecular weight (g/mol)") +
  ylab("rotatable bonds") +
  theme(legend.position = "right")
```

## Logistic Regression

I used the `mlr` package for logistic regression with repeated k-fold cross validation with 20 repetitions of 10 folds each. The performance metrics of accuracy, false positive rate, and false negative rate are in the table below the code block.

``` {r message = FALSE, warning = FALSE}
# Create the task
delaneyTask <- makeClassifTask(data = train, 
                               target = "solubility.above.or.below.median")

# Create the learner
learner <- makeLearner("classif.logreg", predict.type = "prob")

# Create k-fold cross validation
kFold <- makeResampleDesc(method = "RepCV", folds = 10, reps = 20, stratify = TRUE)

# Now run the cross validation
result <- resample(learner = learner, 
                   task = delaneyTask, 
                   resampling = kFold,
                   measures = list(acc, fpr, fnr),
                   models = TRUE)

knitr::kable(result$aggr, col.names = FALSE)
```

Finally, I pulled out the first model of the 200 created and plotted performance metrics as a function of logistic regression threshold:

``` {r, fig.width = 6, fig.height = 3, fig.align = "center", fig.cap = "Figure 3: Performance curves for first model"}
test_task <- makeClassifTask(data = test, target = "solubility.above.or.below.median")
firstModel <- result$models[[1]]
pred <- predict(firstModel, test_task)
df <- generateThreshVsPerfData(pred, measures = list(fpr, tpr, mmce))
print(plotThreshVsPerf(df))
```

Finally, I made the ROC curve plot:

``` {r, fig.width = 3, fig.height = 3, fig.align = "center", fig.cap = "Figure 4: ROC for first model"}
plotROCCurves(df)
```

### Logistic regression AUROC

The logistic regression AUROC for the first model in the run is:

``` {r}
performance(pred, auc)
```
